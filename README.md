# MLProject1 ‚Äî Student Performance Classifier

A compact, end‚Äëto‚Äëend machine‚Äëlearning project that trains a classifier to predict **`GradeClass` (0‚Äì4)** from student features, and serves it as a **Flask API**. The repo includes reproducible training scripts, a persisted preprocessing pipeline, a model selection routine over 5 algorithms, and a production‚Äëready `/predict` endpoint.

---

## Highlights

* **Clean pipeline**: data ingestion ‚Üí transformation (ColumnTransformer) ‚Üí model selection (GridSearchCV) ‚Üí persisted artifacts.
* **Strong baseline**: best model (in our run) = **GradientBoostingClassifier** with \~**0.916** accuracy and **0.869** F1‚Äëmacro on the held‚Äëout test set.
* **Portable artifacts**: `artifact/preprocessor.pkl` + `artifact/model.pkl` load directly in the API.
* **Simple REST API**: `/health`, `/` and `/predict` with JSON input; returns predictions (and probabilities when supported).
---

## üìÅ Project Structure

```
MLPROJECT1/
‚îú‚îÄ artifact/
‚îÇ  ‚îú‚îÄ data.csv         
‚îÇ  ‚îú‚îÄ train.csv          # 80% split
‚îÇ  ‚îú‚îÄ test.csv           # 20% split
‚îÇ  ‚îú‚îÄ preprocessor.pkl   
‚îÇ  ‚îî‚îÄ model.pkl          # best trained model
‚îú‚îÄ app.py               
‚îú‚îÄ requirements.txt 
‚îú‚îÄ runtime.txt        
‚îú‚îÄ .ebignore            
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ components/
‚îÇ  ‚îÇ  ‚îú‚îÄ data_ingestion.py
‚îÇ  ‚îÇ  ‚îú‚îÄ data_transformation.py
‚îÇ  ‚îÇ  ‚îî‚îÄ model_trainer.py
‚îÇ  ‚îú‚îÄ pipeline/
‚îÇ  ‚îÇ  ‚îî‚îÄ train_pipeline.py    
‚îÇ  ‚îú‚îÄ logger.py, exception.py, utils.py, __init__.py
‚îÇ  ‚îî‚îÄ __init__.py
‚îú‚îÄ notebook/            
‚îú‚îÄ clean.py              # helper to clean notebook widget metadata
‚îî‚îÄ README.md             # this file
```

---

## üß† Problem & Data

The goal is to predict **`GradeClass`** ‚àà {0,1,2,3,4}. Typical features used (as wired in the transformer):

* **Numeric**: `Age`, `StudyTimeWeekly`, `Absences`, `GPA`
* **Categorical**: `Gender`, `Ethnicity`, `ParentalEducation`, `Tutoring`, `ParentalSupport`, `Extracurricular`, `Sports`, `Music`, `Volunteering`
* **ID (dropped)**: `StudentID`
* **Target**: `GradeClass`

> If your CSV schema differs, update the lists inside `DataTransformation.get_data_transformer_object()`.

Class distribution example (train): 4.0‚âà55%, 3.0‚âà19%, 2.0‚âà18%, 1.0‚âà12%, 0.0‚âà5% (mild imbalance).

---

## üõ†Ô∏è Setup

### 1) Create & activate a virtual environment

**Windows PowerShell**

```powershell
python -m venv .venv
.\.venv\Scripts\activate
```

### 2) Install minimal inference dependencies

(versions pinned to training env ‚Äî edit as needed)

```text
pandas
numpy
seaborn
scikit-learn
catboost
xgboost
imblearn
```

```powershell
pip install -r requirements.txt
```


---

## Training Pipeline

You can run each component separately


1. **Data ingestion** (reads `notebook/data/student_data.csv`, writes splits under `artifact/`)

```powershell
python src/components/data_ingestion.py
```

2. **Data transformation** (fits preprocessor, saves `preprocessor.pkl`)

```powershell
python src/components/data_transformation.py
```

3. **Model training** (grid‚Äësearch over 5 models, saves best `model.pkl` and `model_report.json`)

```powershell
python src/components/model_trainer.py
```


### What the transformer does

* **Numeric pipeline**: median imputation ‚Üí `StandardScaler`
* **Categorical pipeline**: most‚Äëfrequent imputation ‚Üí `OneHotEncoder(handle_unknown="ignore")` ‚Üí `StandardScaler(with_mean=False)`
* Drops `StudentID` and the target from features.

### Model selection

* Tries: Logistic Regression, Random Forest, Gradient Boosting (GBDT), SVC, KNN
* Uses `GridSearchCV(cv=5)`. The current config selects by **F1‚Äëmacro** (safer with imbalance) and also reports **accuracy**. Set `scoring="accuracy"` in `model_trainer.py` to select by accuracy instead.

### Inspect the report

```python
import json
r = json.load(open("artifact/model_report.json"))
print(r["best_model"])               
print(r["best_model_cv"])             # best params + CV score
print(r["test_metrics"])              # accuracy & f1_macro on held‚Äëout test
```

---

## üöÄ Local Inference (Flask API)

Start the dev server:

```powershell
python app.py
# Running on http://127.0.0.1:8080
```

### Health

```powershell
Invoke-RestMethod http://127.0.0.1:8080/health -Method GET
```

### Predict (PowerShell example)

```powershell
$body = @{
  instances = @(@{
    Age=17; StudyTimeWeekly=8; Absences=3; GPA=3.4;
    Gender="F"; Ethnicity="GroupA"; ParentalEducation="Bachelors";
    Tutoring="Yes"; ParentalSupport="High"; Extracurricular="Yes";
    Sports="No"; Music="Yes"; Volunteering="No"
  })
} | ConvertTo-Json -Depth 5

Invoke-RestMethod http://127.0.0.1:8080/predict -Method POST -ContentType "application/json" -Body $body
```

**Response**

```json
{
  "predictions": [1],
  "probabilities": [{"0": 0.005, "1": 0.949, "2": 0.013, "3": 0.017, "4": 0.015}]
}
```

### Notes on inputs

* Order of keys doesn‚Äôt matter; missing keys are filled with `NaN` and imputed by the pipeline.
* Unknown categories are safely ignored (`OneHotEncoder(handle_unknown="ignore")`).
* The endpoint accepts **one object** or a list of objects, or `{ "instances": [...] }`.

### Python client snippet

```python
python quick_test.py --offline
```

to test on a default data <br>

change: <br>

DEFAULT_ROW = {
    "Age": 17, "StudyTimeWeekly": 8, "Absences": 3, "GPA": 3.4,
    "Gender": "F", "Ethnicity": "GroupA", "ParentalEducation": "Bachelors",
    "Tutoring": "Yes", "ParentalSupport": "High", "Extracurricular": "Yes",
    "Sports": "No", "Music": "Yes", "Volunteering": "No"
}

<br>

to test on custom data
---